{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6c2fffe42b92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Important libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Important libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up GPU\n",
    "DEVICE = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "MEAN = 0.5,0.5,0.5\n",
    "STD = 0.5,0.5,0.5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LR = 0.00001\n",
    "N_WORKERS = 12\n",
    "IMAGE_SIZE = (600, 600)\n",
    "PATH_TRAIN = '/nas/home/slnagark/Genome/res/crisis-computing/data/Training_data'\n",
    "PATH_TEST =  '/nas/home/slnagark/Genome/res/crisis-computing/data/Testing_data'\n",
    "CLASSES = {0:\"Informative\"  , 1:\"Non-Informative\"}\n",
    "FINAL_CKPT = '/nas/home/slnagark/Genome/res/checkpoints/resnet50_bceloss_final_model.pth'\n",
    "\n",
    "# Resnet50 Architecture\n",
    "class Resnet(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Resnet,self).__init__()\n",
    "    self.resnet = torchvision.models.resnet50(pretrained=True)\n",
    "    # Following step gives us all layers except last one.\n",
    "    modules = list(self.resnet.children())[:-1]\n",
    "    self.resnet = torch.nn.Sequential(*modules)\n",
    "    # Freeze the model parameters for transfer learning.\n",
    "    for params in self.resnet.parameters():\n",
    "      params.requires_grad = False\n",
    "    \n",
    "    # Classification head of the model.\n",
    "    self.head = torch.nn.Sequential(\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(in_features=2048, out_features=2048, bias=True),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(0.3),\n",
    "        torch.nn.BatchNorm1d(2048),\n",
    "        torch.nn.Linear(2048, 1, bias=True),\n",
    "        torch.nn.Sigmoid())\n",
    "    \n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.resnet(x)\n",
    "    x = self.head(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transforms_train():\n",
    "    \"\"\"\n",
    "    Returns transformations on training dataset.\n",
    "    params: mean - channel-wise mean of data\n",
    "            std - channel-wise std of data\n",
    "    \"\"\"\n",
    "    train_transform = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(p=0.6),\n",
    "                      torchvision.transforms.RandomAffine(degrees=10,shear=(0.05,0.15)),\n",
    "                      torchvision.transforms.Resize(IMAGE_SIZE, interpolation=Image.BILINEAR),\n",
    "                      torchvision.transforms.ToTensor(),\n",
    "                      torchvision.transforms.Normalize(MEAN, STD)])\n",
    "    \n",
    "    return train_transform\n",
    "\n",
    "def transforms_test():\n",
    "    \"\"\"\n",
    "    Returns transformations on testing dataset.\n",
    "    params: mean - channel-wise mean of data\n",
    "            std - channel-wise std of data\n",
    "    \"\"\"\n",
    "    test_transform = torchvision.transforms.Compose([torchvision.transforms.Resize(IMAGE_SIZE, interpolation=Image.BILINEAR),\n",
    "                                                 torchvision.transforms.ToTensor(),\n",
    "                                                 torchvision.transforms.Normalize(MEAN, STD)])\n",
    "    return test_transform\n",
    "\n",
    "\n",
    "def get_dataloaders(train_transform, test_transform):\n",
    "    \"\"\"\n",
    "    returns train, validation and test dataloafer objects\n",
    "    params: train_transform - Augmentation for trainset\n",
    "            test_transform - Augmentation for testset\n",
    "            batch_size - size of batch\n",
    "            n_workers - number of workers\n",
    "    \"\"\"\n",
    "    training = torchvision.datasets.ImageFolder(root=PATH_TRAIN, transform=train_transform)\n",
    "    validation = torchvision.datasets.ImageFolder(root=PATH_TRAIN, transform=test_transform)\n",
    "    testing = torchvision.datasets.ImageFolder(root=PATH_TEST, transform=test_transform)\n",
    "\n",
    "    # sample part data for validation pupose. Train-val split = 80-20\n",
    "    n_train = len(training)\n",
    "    indices = list(range(n_train))\n",
    "    split = int(np.floor(0.2*n_train))\n",
    "    train_idx, val_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_idx)\n",
    "\n",
    "\n",
    "    train_set = torch.utils.data.DataLoader(training,batch_size = batch_size,  sampler=train_sampler, num_workers=N_WORKERS)\n",
    "    val_set = torch.utils.data.DataLoader(training, batch_size = batch_size, sampler=valid_sampler, num_workers=N_WORKERS)\n",
    "    test_set = torch.utils.data.DataLoader(testing, batch_size = batch_size, shuffle=True, num_workers=N_WORKERS)\n",
    "\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def train_loop(model, dataset, flag):\n",
    "  \"\"\"\n",
    "  returns loss and accuracy of the model for 1 epoch.\n",
    "  params: model -  resnet50\n",
    "          dataset - train or val dataset\n",
    "          flag - \"train\" for training, \"val\" for validation\n",
    "  \"\"\"\n",
    "\n",
    "  for ind, (image, label) in enumerate(dataset):\n",
    "      image = image.to(device)\n",
    "      label = label.type(torch.float).to(device)\n",
    "\n",
    "      if flag == \"train\":\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "      output = model(image)\n",
    "      \n",
    "      loss = criterion(output, label.unsqueeze(1))\n",
    "      epoch_loss += loss.item()\n",
    "      predicted = torch.round(output).squeeze(-1) \n",
    "      total += label.size(0)\n",
    "      correct += (predicted==label).sum().item()\n",
    "      loss.backward()\n",
    "\n",
    "      if flag==\"train\":\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_accuracy = 100*correct/total\n",
    "    epoch_loss = epoch_loss/len(train_set)\n",
    "  \n",
    "  return epoch_loss, epoch_accuracy\n",
    "\n",
    "\n",
    "def train(train, val, model, optimizer, criterion):\n",
    "  \"\"\"\n",
    "  returns train and validation losses of the model over complete training.\n",
    "  params: train - train dataset\n",
    "          val - validation dataset\n",
    "          optimizer - optimizer for training\n",
    "          criterion - loss function\n",
    "  \"\"\"\n",
    "  train_losses = []\n",
    "  val_losses = []\n",
    "  print(\"Training start...\")\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    print(\"Running Epoch {}\".format(epoch+1))\n",
    "    \n",
    "    epoch_train_loss, train_accuracy = train_loop(model,train, \"train\")\n",
    "    train_losses.append(epoch_train_loss)\n",
    "  \n",
    "    if (epoch+1)%25==0:\n",
    "      ckpt_path = '/nas/home/slnagark/Genome/res/checkpoints/resnet50_bceloss_epoch_{}.pth'.format(epoch+1)\n",
    "      torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "      epoch_val_loss, validation_accuracy = train_loop(model, val, \"val\")\n",
    "      val_losses.append(epoch_val_loss)\n",
    "  \n",
    "    print(\"Training loss: {0:.4f}  Train Accuracy: {1:0.2f}\".format(epoch_train_loss, train_accuracy))\n",
    "    print(\"Validation loss: {0:.4f}  Validation Accuracy: {1:0.2f}\".format(epoch_val_loss, validation_accuracy))\n",
    "    print(\"--------------------------------------------------------\")\n",
    "\n",
    "  print(\"Training done...\")\n",
    "  print(\"Model saved!\")\n",
    "  final_ckpt = '/nas/home/slnagark/Genome/res/checkpoints/resnet50_bceloss_final_model.pth'\n",
    "  torch.save(model.state_dict(), final_ckpt)\n",
    "\n",
    "  return train_losses, val_losses\n",
    "\n",
    "def test(model, test):\n",
    "  \"\"\"\n",
    "  returns output probabilites and prediction classes\n",
    "  params: model - model for testing\n",
    "          test - test dataset\n",
    "  \"\"\"\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.eval()\n",
    "  with torch.no_grad():  \n",
    "    for image, label in test_set:\n",
    "\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.type(torch.float).to(DEVICE)\n",
    "        output_prob = model(image)\n",
    "        predicted = torch.round(output).squeeze(-1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "    \n",
    "    test_accuracy = 100*correct/total\n",
    "    print('Test Accuracy: %f %%' %(test_accuracy))\n",
    "\n",
    "  return output_prob, predicted\n",
    "\n",
    "\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    \"\"\"\n",
    "    plots train vs validation loss graph\n",
    "    \n",
    "    \"\"\"\n",
    "    epochs = range(1,EPOCHS+1)\n",
    "    plt.plot(epochs, train_losses, 'g', label='Training loss')\n",
    "    plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
    "    plt.title('Training vs Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch :  1\n",
      "batch :  2\n",
      "batch :  3\n",
      "batch :  4\n",
      "batch :  5\n",
      "batch :  6\n",
      "batch :  7\n",
      "batch :  8\n",
      "batch :  9\n",
      "batch :  10\n",
      "batch :  11\n",
      "batch :  12\n",
      "batch :  13\n",
      "batch :  14\n",
      "batch :  15\n",
      "batch :  16\n",
      "batch :  17\n",
      "batch :  18\n",
      "batch :  19\n",
      "batch :  20\n",
      "batch :  21\n",
      "batch :  22\n",
      "batch :  23\n",
      "batch :  24\n",
      "batch :  25\n",
      "batch :  26\n",
      "batch :  27\n",
      "batch :  28\n",
      "batch :  29\n",
      "batch :  30\n",
      "batch :  31\n",
      "batch :  32\n",
      "batch :  33\n",
      "batch :  34\n",
      "batch :  35\n",
      "batch :  36\n",
      "batch :  37\n",
      "batch :  38\n",
      "Test Accuracy: 88.014981 %\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "  # Initialize model\n",
    "  model = Resnet().to(DEVICE)\n",
    "\n",
    "  #Optimizer initialization\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "\n",
    "  #Loss function initialization\n",
    "  criterion = torch.nn.BCELoss()\n",
    "\n",
    "  train_transform, test_transform = transforms_train(), transforms_test()\n",
    "  train_data, val_data, test_data = get_dataloaders(train_transform, test_transform)\n",
    "\n",
    "  train_loss, val_loss = train(train_data, val_data, model, optimizer, criterion)\n",
    "  plot_loss(train_loss, val_loss)\n",
    "\n",
    "  # load specific model for test\n",
    "  test_model = Resnet().to(DEVICE)\n",
    "  test_model = test_model.load_state_dict(torch.load(FINAL_CKPT))\n",
    "  output_prob, output_class = test(test_model, test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}